{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classify MNIST with Tensorlow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4syBZIMxbMlAvibMTvw0U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azizamirsaidova/delos/blob/main/Classify_MNIST_with_Tensorlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook file classifies the **MNIST using Tensorflow** and conducts the data augmentation."
      ],
      "metadata": {
        "id": "XIh9MuitlRCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import dependencies.**"
      ],
      "metadata": {
        "id": "5SaLNiURlgqn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qahEzyqWTpVW",
        "outputId": "ae02b8f7-b61b-4e8e-f40c-939459356f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import MNIST dataset and split to train and test set.**"
      ],
      "metadata": {
        "id": "pUlZexZplqh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ],
      "metadata": {
        "id": "e06AUcpHTw8r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conduct data augmentation by rotating the images by 180 degrees.**"
      ],
      "metadata": {
        "id": "kM6xJcVXl5wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_180 = tf.image.rot90(x_train, k=2)"
      ],
      "metadata": {
        "id": "erliZsHxy2RE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_180 = tf.image.rot90(x_test, k=2)"
      ],
      "metadata": {
        "id": "a7Byp7_5j5BU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the batch size and shuffle the dataset.**"
      ],
      "metadata": {
        "id": "NKJNlJi7mHaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train_180, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test_180, y_test)).batch(32)"
      ],
      "metadata": {
        "id": "qqIlRiI1T5sB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build MNIST Tensorflow Keras model with Convulational Neural Network and RELU activation function.**"
      ],
      "metadata": {
        "id": "T2knxbsumOPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST(Model):\n",
        "  def __init__(self):\n",
        "    super(MNIST, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# An instance of the model\n",
        "model = MNIST()"
      ],
      "metadata": {
        "id": "Zh9aALJwT8E6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sparse Categorical cross entropy loss and Adam optimizer is used.**"
      ],
      "metadata": {
        "id": "fjWKMMcynm3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "#optimizer = tf.keras.optimizers.SGD(learning_rate=1.0)"
      ],
      "metadata": {
        "id": "P94Z-AtzUCv5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics used to test the performance:**\n",
        "*   Loss\n",
        "*   Accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "jnGMXpqhn9yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "metadata": {
        "id": "eDZjmm6oUGAb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.GradientTape() is used to teain the model.**"
      ],
      "metadata": {
        "id": "8Dwco0RRoQq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "metadata": {
        "id": "7JLJuJGqUJSS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model is tested.**"
      ],
      "metadata": {
        "id": "pKmXTLxpofzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(images, labels):\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "metadata": {
        "id": "05X7kr1EUPTd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MNIST Classifier trained on epoch 6 with accuracy of 98.45.**"
      ],
      "metadata": {
        "id": "zmq4BctsoleV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 6\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8EmlQ5_USqs",
        "outputId": "bfa78333-0a8e-45e0-b857-6b364a880faa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.003106481395661831, Accuracy: 99.88166809082031, Test Loss: 0.08041059970855713, Test Accuracy: 98.44999694824219\n",
            "Epoch 2, Loss: 0.0036859021056443453, Accuracy: 99.8566665649414, Test Loss: 0.07642525434494019, Test Accuracy: 98.55999755859375\n",
            "Epoch 3, Loss: 0.0024309020955115557, Accuracy: 99.92666625976562, Test Loss: 0.09809140861034393, Test Accuracy: 98.27999877929688\n",
            "Epoch 4, Loss: 0.004398781340569258, Accuracy: 99.86333465576172, Test Loss: 0.07958949357271194, Test Accuracy: 98.47000122070312\n",
            "Epoch 5, Loss: 0.0030536337289959192, Accuracy: 99.89666748046875, Test Loss: 0.08075742423534393, Test Accuracy: 98.5\n",
            "Epoch 6, Loss: 0.00030101474840193987, Accuracy: 99.99500274658203, Test Loss: 0.09532584995031357, Test Accuracy: 98.45999908447266\n"
          ]
        }
      ]
    }
  ]
}